{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import spacy\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchtext.vocab import FastText\n",
    "np.random.seed(0)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext = FastText(\"simple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    df = pd.read_csv(path, header=None, nrows=3000, skiprows=1, usecols=[1,2,3])\n",
    "    df.rename({1: 'star', 2: 'rating1', 3: 'rating2'}, axis=1, inplace=True)\n",
    "    df['review'] = df['rating1'] + ' ' + df['rating2']\n",
    "    df.drop(columns=['rating1', 'rating2'], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, train_size=0.8):\n",
    "    df_idx = [i for i in range(len(df))]\n",
    "    np.random.shuffle(df_idx)\n",
    "    len_train = int(len(df) * train_size)\n",
    "    df_train = df.iloc[:len_train].reset_index(drop=True)\n",
    "    df_test = df.iloc[len_train:].reset_index(drop=True)\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(sentence):\n",
    "    \"\"\"\n",
    "    Get rid of special symbols, lower case the words.\n",
    "    return token list\n",
    "    \"\"\"\n",
    "    doc = nlp(sentence)\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_punct and not token.is_space and not token.is_stop]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_encoder(token, vec):\n",
    "    if token == \"<pad>\":\n",
    "        return 1\n",
    "    else:\n",
    "        try:\n",
    "            return vec.stoi[token]\n",
    "        except:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(tokens, vec):\n",
    "    return [token_encoder(token, vec) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(list_of_idx, max_seq_len, padding_index=1):\n",
    "    output = list_of_idx + (max_seq_len - len(list_of_idx))*[padding_index]\n",
    "    return output[:max_seq_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataClass(Dataset):\n",
    "    def __init__(self, df, max_seq_len=32):\n",
    "        self.max_seq_len = max_seq_len\n",
    "        train_iter = iter(df.review.values)\n",
    "        self.vec = FastText(\"simple\")\n",
    "        self.vec.vectors[1] = -torch.ones(self.vec.vectors[1].shape[0])\n",
    "        self.vec.vectors[0] = torch.zeros(self.vec.vectors[0].shape[0])\n",
    "        self.vectorizer = lambda x: self.vec.vectors[x]\n",
    "        self.labels = df.star\n",
    "        sequences = [padding(encoder(preprocessing(sequence), self.vec), max_seq_len) for sequence in df.review.tolist()]\n",
    "        self.sequences = sequences\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        assert len(self.sequences[i]) == self.max_seq_len\n",
    "        return self.sequences[i], self.labels[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 1, 2, 4])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "df = load_data('/Users/szokirov/Documents/GitHub/strive_practice/Chapter 03/18. Semantic Analysis/.data/Amazon/3000test.csv')\n",
    "df.star = df.star.apply(lambda x: int(x) -1)\n",
    "\n",
    "train_df, test_df = train_test_split(df)\n",
    "train_df, test_df = DataClass(train_df), DataClass(test_df)\n",
    "df.star.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 1, 2, 4])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.star.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_train(batch, vectorizer=train_df.vectorizer):\n",
    "    inputs = torch.stack([torch.stack([vectorizer(token) for token in sentence[0]]) for sentence in batch])\n",
    "    target = torch.LongTensor([item[1] for item in batch])\n",
    "    return inputs, target\n",
    "\n",
    "def collate_test(batch, vectorizer=test_df.vectorizer):\n",
    "    inputs = torch.stack([torch.stack([vectorizer(token) for token in sentence[0]]) for sentence in batch])\n",
    "    target = torch.LongTensor([item[1] for item in batch])\n",
    "    return inputs, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_df, batch_size=BATCH_SIZE, collate_fn=collate_train, shuffle=True)\n",
    "test_loader = DataLoader(test_df, batch_size=BATCH_SIZE, collate_fn=collate_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "emb_dim = 300\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, max_seq_len, emb_dim, hidden1=16, hidden2=16):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(max_seq_len*emb_dim, hidden1)\n",
    "        self.fc2 = nn.Linear(hidden1, hidden2)\n",
    "        self.fc3 = nn.Linear(hidden2, 5)\n",
    "        self.out = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        x = F.relu(self.fc1(inputs.squeeze(1).float()))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return self.out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (fc1): Linear(in_features=9600, out_features=16, bias=True)\n",
       "  (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "  (fc3): Linear(in_features=16, out_features=5, bias=True)\n",
       "  (out): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_SEQ_LEN = 32\n",
    "model = Classifier(MAX_SEQ_LEN, 300, 16, 16)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Only train the classifier parameters, feature parameters are frozen\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/300, Train loss: 0.5278, Test loss: 5.1843, Accuracy: 0.2341\n",
      "Epoch: 2/300, Train loss: 0.5298, Test loss: 5.4449, Accuracy: 0.2473\n",
      "Epoch: 3/300, Train loss: 0.5250, Test loss: 5.3440, Accuracy: 0.2467\n",
      "Epoch: 4/300, Train loss: 0.5107, Test loss: 5.5062, Accuracy: 0.2346\n",
      "Epoch: 5/300, Train loss: 0.5430, Test loss: 5.4186, Accuracy: 0.2396\n",
      "Epoch: 6/300, Train loss: 0.5154, Test loss: 5.6593, Accuracy: 0.2346\n",
      "Epoch: 7/300, Train loss: 0.5069, Test loss: 5.6326, Accuracy: 0.2396\n",
      "Epoch: 8/300, Train loss: 0.5409, Test loss: 5.4605, Accuracy: 0.2292\n",
      "Epoch: 9/300, Train loss: 0.5114, Test loss: 5.4704, Accuracy: 0.2412\n",
      "Epoch: 10/300, Train loss: 0.4963, Test loss: 5.8247, Accuracy: 0.2292\n",
      "Epoch: 11/300, Train loss: 0.5074, Test loss: 5.6471, Accuracy: 0.2462\n",
      "Epoch: 12/300, Train loss: 0.4953, Test loss: 5.9152, Accuracy: 0.2478\n",
      "Epoch: 13/300, Train loss: 0.5002, Test loss: 6.0744, Accuracy: 0.2045\n",
      "Epoch: 14/300, Train loss: 0.4998, Test loss: 6.1178, Accuracy: 0.2363\n",
      "Epoch: 15/300, Train loss: 0.4852, Test loss: 6.0895, Accuracy: 0.2412\n",
      "Epoch: 16/300, Train loss: 0.4805, Test loss: 6.2460, Accuracy: 0.2259\n",
      "Epoch: 17/300, Train loss: 0.4843, Test loss: 6.3572, Accuracy: 0.2390\n",
      "Epoch: 18/300, Train loss: 0.4787, Test loss: 6.4839, Accuracy: 0.2341\n",
      "Epoch: 19/300, Train loss: 0.4903, Test loss: 6.4758, Accuracy: 0.2396\n",
      "Epoch: 20/300, Train loss: 0.4776, Test loss: 6.6618, Accuracy: 0.2297\n",
      "Epoch: 21/300, Train loss: 0.4951, Test loss: 6.5085, Accuracy: 0.2396\n",
      "Epoch: 22/300, Train loss: 0.5038, Test loss: 6.5067, Accuracy: 0.2429\n",
      "Epoch: 23/300, Train loss: 0.4902, Test loss: 6.4890, Accuracy: 0.2396\n",
      "Epoch: 24/300, Train loss: 0.5206, Test loss: 6.6831, Accuracy: 0.2325\n",
      "Epoch: 25/300, Train loss: 0.4952, Test loss: 6.5536, Accuracy: 0.2314\n",
      "Epoch: 26/300, Train loss: 0.4812, Test loss: 6.6414, Accuracy: 0.2325\n",
      "Epoch: 27/300, Train loss: 0.4889, Test loss: 6.5815, Accuracy: 0.2363\n",
      "Epoch: 28/300, Train loss: 0.4917, Test loss: 6.7303, Accuracy: 0.2056\n",
      "Epoch: 29/300, Train loss: 0.4815, Test loss: 6.9273, Accuracy: 0.2325\n",
      "Epoch: 30/300, Train loss: 0.4744, Test loss: 6.8254, Accuracy: 0.2379\n",
      "Epoch: 31/300, Train loss: 0.4773, Test loss: 6.9319, Accuracy: 0.2226\n",
      "Epoch: 32/300, Train loss: 0.4703, Test loss: 6.9811, Accuracy: 0.2379\n",
      "Epoch: 33/300, Train loss: 0.4754, Test loss: 7.0455, Accuracy: 0.2379\n",
      "Epoch: 34/300, Train loss: 0.4666, Test loss: 7.3325, Accuracy: 0.2330\n",
      "Epoch: 35/300, Train loss: 0.4611, Test loss: 7.1863, Accuracy: 0.2379\n",
      "Epoch: 36/300, Train loss: 0.4680, Test loss: 7.0029, Accuracy: 0.2346\n",
      "Epoch: 37/300, Train loss: 0.4683, Test loss: 7.4840, Accuracy: 0.1963\n",
      "Epoch: 38/300, Train loss: 0.4599, Test loss: 8.0316, Accuracy: 0.2177\n",
      "Epoch: 39/300, Train loss: 0.4883, Test loss: 7.2654, Accuracy: 0.2368\n",
      "Epoch: 40/300, Train loss: 0.6747, Test loss: 5.2914, Accuracy: 0.2209\n",
      "Epoch: 41/300, Train loss: 0.6737, Test loss: 5.1439, Accuracy: 0.2478\n",
      "Epoch: 42/300, Train loss: 0.5544, Test loss: 6.1082, Accuracy: 0.2138\n",
      "Epoch: 43/300, Train loss: 0.5232, Test loss: 5.7037, Accuracy: 0.2215\n",
      "Epoch: 44/300, Train loss: 0.5048, Test loss: 5.6607, Accuracy: 0.2144\n",
      "Epoch: 45/300, Train loss: 0.4868, Test loss: 5.9354, Accuracy: 0.1963\n",
      "Epoch: 46/300, Train loss: 0.4718, Test loss: 5.9927, Accuracy: 0.2166\n",
      "Epoch: 47/300, Train loss: 0.4677, Test loss: 6.1158, Accuracy: 0.2198\n",
      "Epoch: 48/300, Train loss: 0.4695, Test loss: 6.3368, Accuracy: 0.2209\n",
      "Epoch: 49/300, Train loss: 0.4709, Test loss: 6.3955, Accuracy: 0.2177\n",
      "Epoch: 50/300, Train loss: 0.4700, Test loss: 6.4117, Accuracy: 0.2116\n",
      "Epoch: 51/300, Train loss: 0.4602, Test loss: 6.4696, Accuracy: 0.2198\n",
      "Epoch: 52/300, Train loss: 0.4702, Test loss: 6.4272, Accuracy: 0.2215\n",
      "Epoch: 53/300, Train loss: 0.4724, Test loss: 6.5146, Accuracy: 0.2248\n",
      "Epoch: 54/300, Train loss: 0.4679, Test loss: 6.4504, Accuracy: 0.2281\n",
      "Epoch: 55/300, Train loss: 0.4640, Test loss: 6.9075, Accuracy: 0.2242\n",
      "Epoch: 56/300, Train loss: 0.4646, Test loss: 6.9845, Accuracy: 0.2177\n",
      "Epoch: 57/300, Train loss: 0.5316, Test loss: 6.7724, Accuracy: 0.2385\n",
      "Epoch: 58/300, Train loss: 0.4957, Test loss: 6.5438, Accuracy: 0.2182\n",
      "Epoch: 59/300, Train loss: 0.5036, Test loss: 6.3857, Accuracy: 0.2188\n",
      "Epoch: 60/300, Train loss: 0.4624, Test loss: 6.6671, Accuracy: 0.2209\n",
      "Epoch: 61/300, Train loss: 0.4598, Test loss: 6.6701, Accuracy: 0.2078\n",
      "Epoch: 62/300, Train loss: 0.4588, Test loss: 7.0261, Accuracy: 0.2127\n",
      "Epoch: 63/300, Train loss: 0.4529, Test loss: 7.0231, Accuracy: 0.2231\n",
      "Epoch: 64/300, Train loss: 0.4515, Test loss: 7.0720, Accuracy: 0.1897\n",
      "Epoch: 65/300, Train loss: 0.4508, Test loss: 7.2110, Accuracy: 0.2177\n",
      "Epoch: 66/300, Train loss: 0.4588, Test loss: 7.0717, Accuracy: 0.2166\n",
      "Epoch: 67/300, Train loss: 0.4620, Test loss: 7.3789, Accuracy: 0.2242\n",
      "Epoch: 68/300, Train loss: 0.4600, Test loss: 7.6681, Accuracy: 0.2193\n",
      "Epoch: 69/300, Train loss: 0.5114, Test loss: 6.8129, Accuracy: 0.2264\n",
      "Epoch: 70/300, Train loss: 0.5078, Test loss: 7.1612, Accuracy: 0.2111\n",
      "Epoch: 71/300, Train loss: 0.4904, Test loss: 7.3634, Accuracy: 0.2111\n",
      "Epoch: 72/300, Train loss: 0.4705, Test loss: 7.1675, Accuracy: 0.2242\n",
      "Epoch: 73/300, Train loss: 0.4607, Test loss: 7.2197, Accuracy: 0.2198\n",
      "Epoch: 74/300, Train loss: 0.4533, Test loss: 7.6359, Accuracy: 0.2193\n",
      "Epoch: 75/300, Train loss: 0.4630, Test loss: 7.0807, Accuracy: 0.2264\n",
      "Epoch: 76/300, Train loss: 0.4605, Test loss: 7.4320, Accuracy: 0.2242\n",
      "Epoch: 77/300, Train loss: 0.4644, Test loss: 7.2738, Accuracy: 0.2341\n",
      "Epoch: 78/300, Train loss: 0.5229, Test loss: 7.0981, Accuracy: 0.2127\n",
      "Epoch: 79/300, Train loss: 0.5145, Test loss: 7.8530, Accuracy: 0.2094\n",
      "Epoch: 80/300, Train loss: 0.4821, Test loss: 7.6028, Accuracy: 0.2346\n",
      "Epoch: 81/300, Train loss: 0.5801, Test loss: 6.7732, Accuracy: 0.2484\n",
      "Epoch: 82/300, Train loss: 0.4970, Test loss: 6.7706, Accuracy: 0.2308\n",
      "Epoch: 83/300, Train loss: 0.4659, Test loss: 6.9831, Accuracy: 0.2325\n",
      "Epoch: 84/300, Train loss: 0.4624, Test loss: 7.0324, Accuracy: 0.2220\n",
      "Epoch: 85/300, Train loss: 0.4717, Test loss: 6.7032, Accuracy: 0.2346\n",
      "Epoch: 86/300, Train loss: 0.4621, Test loss: 7.0130, Accuracy: 0.2330\n",
      "Epoch: 87/300, Train loss: 0.4570, Test loss: 6.9628, Accuracy: 0.2379\n",
      "Epoch: 88/300, Train loss: 0.4504, Test loss: 6.8373, Accuracy: 0.2325\n",
      "Epoch: 89/300, Train loss: 0.4505, Test loss: 7.0924, Accuracy: 0.2368\n",
      "Epoch: 90/300, Train loss: 0.4517, Test loss: 7.0560, Accuracy: 0.1952\n",
      "Epoch: 91/300, Train loss: 0.4480, Test loss: 7.1850, Accuracy: 0.2303\n",
      "Epoch: 92/300, Train loss: 0.4468, Test loss: 7.3153, Accuracy: 0.2336\n",
      "Epoch: 93/300, Train loss: 0.4462, Test loss: 7.2467, Accuracy: 0.2001\n",
      "Epoch: 94/300, Train loss: 0.4458, Test loss: 7.3396, Accuracy: 0.1985\n",
      "Epoch: 95/300, Train loss: 0.4457, Test loss: 7.3913, Accuracy: 0.2319\n",
      "Epoch: 96/300, Train loss: 0.4454, Test loss: 7.3839, Accuracy: 0.1985\n",
      "Epoch: 97/300, Train loss: 0.4455, Test loss: 7.5194, Accuracy: 0.2001\n",
      "Epoch: 98/300, Train loss: 0.4451, Test loss: 7.5387, Accuracy: 0.2319\n",
      "Epoch: 99/300, Train loss: 0.4449, Test loss: 7.5699, Accuracy: 0.2286\n",
      "Epoch: 100/300, Train loss: 0.4450, Test loss: 7.5979, Accuracy: 0.2303\n",
      "Epoch: 101/300, Train loss: 0.4450, Test loss: 7.6278, Accuracy: 0.2286\n",
      "Epoch: 102/300, Train loss: 0.4445, Test loss: 7.7180, Accuracy: 0.2336\n",
      "Epoch: 103/300, Train loss: 0.4448, Test loss: 7.7197, Accuracy: 0.2319\n",
      "Epoch: 104/300, Train loss: 0.4447, Test loss: 7.7954, Accuracy: 0.2336\n",
      "Epoch: 105/300, Train loss: 0.4444, Test loss: 7.8271, Accuracy: 0.2368\n",
      "Epoch: 106/300, Train loss: 0.4446, Test loss: 7.8359, Accuracy: 0.2319\n",
      "Epoch: 107/300, Train loss: 0.4448, Test loss: 7.9065, Accuracy: 0.2034\n",
      "Epoch: 108/300, Train loss: 0.4446, Test loss: 7.9660, Accuracy: 0.2352\n",
      "Epoch: 109/300, Train loss: 0.4447, Test loss: 7.9960, Accuracy: 0.2352\n",
      "Epoch: 110/300, Train loss: 0.4444, Test loss: 8.0166, Accuracy: 0.2336\n",
      "Epoch: 111/300, Train loss: 0.4445, Test loss: 8.0718, Accuracy: 0.2352\n",
      "Epoch: 112/300, Train loss: 0.4446, Test loss: 8.0703, Accuracy: 0.2319\n",
      "Epoch: 113/300, Train loss: 0.4443, Test loss: 8.1103, Accuracy: 0.2303\n",
      "Epoch: 114/300, Train loss: 0.4446, Test loss: 8.2271, Accuracy: 0.2336\n",
      "Epoch: 115/300, Train loss: 0.4448, Test loss: 8.2309, Accuracy: 0.2385\n",
      "Epoch: 116/300, Train loss: 0.4443, Test loss: 8.2801, Accuracy: 0.2385\n",
      "Epoch: 117/300, Train loss: 0.4443, Test loss: 8.2998, Accuracy: 0.2368\n",
      "Epoch: 118/300, Train loss: 0.4440, Test loss: 8.3352, Accuracy: 0.2319\n",
      "Epoch: 119/300, Train loss: 0.4439, Test loss: 8.3649, Accuracy: 0.2100\n",
      "Epoch: 120/300, Train loss: 0.4442, Test loss: 8.3752, Accuracy: 0.2418\n",
      "Epoch: 121/300, Train loss: 0.4440, Test loss: 8.4943, Accuracy: 0.2133\n",
      "Epoch: 122/300, Train loss: 0.4442, Test loss: 8.4370, Accuracy: 0.2385\n",
      "Epoch: 123/300, Train loss: 0.4440, Test loss: 8.5148, Accuracy: 0.2352\n",
      "Epoch: 124/300, Train loss: 0.4440, Test loss: 8.5163, Accuracy: 0.2352\n",
      "Epoch: 125/300, Train loss: 0.4441, Test loss: 8.5035, Accuracy: 0.2385\n",
      "Epoch: 126/300, Train loss: 0.4439, Test loss: 8.4783, Accuracy: 0.2018\n",
      "Epoch: 127/300, Train loss: 0.6546, Test loss: 7.1833, Accuracy: 0.2023\n",
      "Epoch: 128/300, Train loss: 0.7359, Test loss: 5.7543, Accuracy: 0.2736\n",
      "Epoch: 129/300, Train loss: 0.7335, Test loss: 5.8838, Accuracy: 0.2555\n",
      "Epoch: 130/300, Train loss: 0.6403, Test loss: 6.1879, Accuracy: 0.2555\n",
      "Epoch: 131/300, Train loss: 0.6067, Test loss: 6.5727, Accuracy: 0.2363\n",
      "Epoch: 132/300, Train loss: 0.6185, Test loss: 5.7160, Accuracy: 0.2412\n",
      "Epoch: 133/300, Train loss: 0.6631, Test loss: 5.9433, Accuracy: 0.2500\n",
      "Epoch: 134/300, Train loss: 0.6382, Test loss: 5.9319, Accuracy: 0.2522\n",
      "Epoch: 135/300, Train loss: 0.6344, Test loss: 6.0534, Accuracy: 0.2423\n",
      "Epoch: 136/300, Train loss: 0.6236, Test loss: 6.0921, Accuracy: 0.2489\n",
      "Epoch: 137/300, Train loss: 0.6277, Test loss: 6.0482, Accuracy: 0.2473\n",
      "Epoch: 138/300, Train loss: 0.6263, Test loss: 6.0183, Accuracy: 0.2379\n",
      "Epoch: 139/300, Train loss: 0.6043, Test loss: 6.1411, Accuracy: 0.2484\n",
      "Epoch: 140/300, Train loss: 0.5456, Test loss: 6.4662, Accuracy: 0.2418\n",
      "Epoch: 141/300, Train loss: 0.5147, Test loss: 6.9108, Accuracy: 0.2593\n",
      "Epoch: 142/300, Train loss: 0.4898, Test loss: 6.8150, Accuracy: 0.2188\n",
      "Epoch: 143/300, Train loss: 0.4795, Test loss: 7.0518, Accuracy: 0.2155\n",
      "Epoch: 144/300, Train loss: 0.5706, Test loss: 6.4452, Accuracy: 0.1815\n",
      "Epoch: 145/300, Train loss: 0.5522, Test loss: 6.8856, Accuracy: 0.2615\n",
      "Epoch: 146/300, Train loss: 0.5085, Test loss: 6.9402, Accuracy: 0.2248\n",
      "Epoch: 147/300, Train loss: 0.5290, Test loss: 6.2547, Accuracy: 0.2330\n",
      "Epoch: 148/300, Train loss: 0.4805, Test loss: 6.7474, Accuracy: 0.2193\n",
      "Epoch: 149/300, Train loss: 0.4786, Test loss: 6.8313, Accuracy: 0.2259\n",
      "Epoch: 150/300, Train loss: 0.4982, Test loss: 6.4631, Accuracy: 0.2275\n",
      "Epoch: 151/300, Train loss: 0.4837, Test loss: 6.5155, Accuracy: 0.2379\n",
      "Epoch: 152/300, Train loss: 0.4666, Test loss: 6.7646, Accuracy: 0.2193\n",
      "Epoch: 153/300, Train loss: 0.4634, Test loss: 6.9492, Accuracy: 0.2242\n",
      "Epoch: 154/300, Train loss: 0.4609, Test loss: 7.1019, Accuracy: 0.2144\n",
      "Epoch: 155/300, Train loss: 0.4660, Test loss: 6.9251, Accuracy: 0.2248\n",
      "Epoch: 156/300, Train loss: 0.4543, Test loss: 7.3892, Accuracy: 0.2122\n",
      "Epoch: 157/300, Train loss: 0.4589, Test loss: 7.0516, Accuracy: 0.2242\n",
      "Epoch: 158/300, Train loss: 0.4777, Test loss: 7.1253, Accuracy: 0.2198\n",
      "Epoch: 159/300, Train loss: 0.4705, Test loss: 7.4522, Accuracy: 0.2166\n",
      "Epoch: 160/300, Train loss: 0.4520, Test loss: 7.6834, Accuracy: 0.2116\n",
      "Epoch: 161/300, Train loss: 0.4487, Test loss: 7.6686, Accuracy: 0.1891\n",
      "Epoch: 162/300, Train loss: 0.4592, Test loss: 7.4338, Accuracy: 0.2149\n",
      "Epoch: 163/300, Train loss: 0.4496, Test loss: 7.5522, Accuracy: 0.2198\n",
      "Epoch: 164/300, Train loss: 0.4462, Test loss: 7.6665, Accuracy: 0.2160\n",
      "Epoch: 165/300, Train loss: 0.4457, Test loss: 7.8038, Accuracy: 0.1826\n",
      "Epoch: 166/300, Train loss: 0.4458, Test loss: 7.9642, Accuracy: 0.2089\n",
      "Epoch: 167/300, Train loss: 0.4460, Test loss: 7.8279, Accuracy: 0.2133\n",
      "Epoch: 168/300, Train loss: 0.4451, Test loss: 7.8234, Accuracy: 0.2149\n",
      "Epoch: 169/300, Train loss: 0.4447, Test loss: 7.9062, Accuracy: 0.2166\n",
      "Epoch: 170/300, Train loss: 0.4448, Test loss: 7.9638, Accuracy: 0.2127\n",
      "Epoch: 171/300, Train loss: 0.4447, Test loss: 8.0855, Accuracy: 0.2144\n",
      "Epoch: 172/300, Train loss: 0.4506, Test loss: 8.0953, Accuracy: 0.2177\n",
      "Epoch: 173/300, Train loss: 0.4463, Test loss: 8.1362, Accuracy: 0.2166\n",
      "Epoch: 174/300, Train loss: 0.4445, Test loss: 8.0963, Accuracy: 0.2166\n",
      "Epoch: 175/300, Train loss: 0.4446, Test loss: 8.1101, Accuracy: 0.2133\n",
      "Epoch: 176/300, Train loss: 0.4447, Test loss: 8.2061, Accuracy: 0.2149\n",
      "Epoch: 177/300, Train loss: 0.4442, Test loss: 8.1725, Accuracy: 0.1864\n",
      "Epoch: 178/300, Train loss: 0.4444, Test loss: 8.2211, Accuracy: 0.1864\n",
      "Epoch: 179/300, Train loss: 0.4443, Test loss: 8.2248, Accuracy: 0.2116\n",
      "Epoch: 180/300, Train loss: 0.4443, Test loss: 8.2539, Accuracy: 0.2149\n",
      "Epoch: 181/300, Train loss: 0.4442, Test loss: 8.2844, Accuracy: 0.1864\n",
      "Epoch: 182/300, Train loss: 0.4441, Test loss: 8.3237, Accuracy: 0.2133\n",
      "Epoch: 183/300, Train loss: 0.4440, Test loss: 8.4035, Accuracy: 0.1897\n",
      "Epoch: 184/300, Train loss: 0.4443, Test loss: 8.3729, Accuracy: 0.2100\n",
      "Epoch: 185/300, Train loss: 0.4440, Test loss: 8.3895, Accuracy: 0.2133\n",
      "Epoch: 186/300, Train loss: 0.4446, Test loss: 8.4006, Accuracy: 0.2133\n",
      "Epoch: 187/300, Train loss: 0.4442, Test loss: 8.5026, Accuracy: 0.1880\n",
      "Epoch: 188/300, Train loss: 0.4440, Test loss: 8.5282, Accuracy: 0.2182\n",
      "Epoch: 189/300, Train loss: 0.4438, Test loss: 8.4863, Accuracy: 0.1880\n",
      "Epoch: 190/300, Train loss: 0.4440, Test loss: 8.5612, Accuracy: 0.2182\n",
      "Epoch: 191/300, Train loss: 0.4442, Test loss: 8.5514, Accuracy: 0.2149\n",
      "Epoch: 192/300, Train loss: 0.4444, Test loss: 8.6120, Accuracy: 0.2133\n",
      "Epoch: 193/300, Train loss: 0.4439, Test loss: 8.5925, Accuracy: 0.2133\n",
      "Epoch: 194/300, Train loss: 0.4439, Test loss: 8.6720, Accuracy: 0.2182\n",
      "Epoch: 195/300, Train loss: 0.4439, Test loss: 8.6729, Accuracy: 0.2166\n",
      "Epoch: 196/300, Train loss: 0.4443, Test loss: 8.6836, Accuracy: 0.2182\n",
      "Epoch: 197/300, Train loss: 0.4440, Test loss: 8.7114, Accuracy: 0.2149\n",
      "Epoch: 198/300, Train loss: 0.4438, Test loss: 8.7496, Accuracy: 0.2166\n",
      "Epoch: 199/300, Train loss: 0.4437, Test loss: 8.7859, Accuracy: 0.2182\n",
      "Epoch: 200/300, Train loss: 0.4438, Test loss: 8.7881, Accuracy: 0.2182\n",
      "Epoch: 201/300, Train loss: 0.4439, Test loss: 8.8200, Accuracy: 0.2198\n",
      "Epoch: 202/300, Train loss: 0.4440, Test loss: 8.8695, Accuracy: 0.2182\n",
      "Epoch: 203/300, Train loss: 0.4443, Test loss: 8.8810, Accuracy: 0.2182\n",
      "Epoch: 204/300, Train loss: 0.4441, Test loss: 8.9448, Accuracy: 0.2198\n",
      "Epoch: 205/300, Train loss: 0.4437, Test loss: 8.9517, Accuracy: 0.2166\n",
      "Epoch: 206/300, Train loss: 0.4441, Test loss: 8.9437, Accuracy: 0.2231\n",
      "Epoch: 207/300, Train loss: 0.4442, Test loss: 9.0206, Accuracy: 0.1897\n",
      "Epoch: 208/300, Train loss: 0.4439, Test loss: 9.0323, Accuracy: 0.1913\n",
      "Epoch: 209/300, Train loss: 0.4442, Test loss: 9.0221, Accuracy: 0.2198\n",
      "Epoch: 210/300, Train loss: 0.4439, Test loss: 9.0856, Accuracy: 0.2166\n",
      "Epoch: 211/300, Train loss: 0.4440, Test loss: 9.0675, Accuracy: 0.1913\n",
      "Epoch: 212/300, Train loss: 0.4440, Test loss: 9.1214, Accuracy: 0.2198\n",
      "Epoch: 213/300, Train loss: 0.4439, Test loss: 9.1593, Accuracy: 0.2166\n",
      "Epoch: 214/300, Train loss: 0.4437, Test loss: 9.1916, Accuracy: 0.1913\n",
      "Epoch: 215/300, Train loss: 0.4439, Test loss: 9.1971, Accuracy: 0.2166\n",
      "Epoch: 216/300, Train loss: 0.4439, Test loss: 9.2218, Accuracy: 0.2182\n",
      "Epoch: 217/300, Train loss: 0.4439, Test loss: 9.2360, Accuracy: 0.2166\n",
      "Epoch: 218/300, Train loss: 0.4438, Test loss: 9.2695, Accuracy: 0.2166\n",
      "Epoch: 219/300, Train loss: 0.4439, Test loss: 9.2727, Accuracy: 0.2166\n",
      "Epoch: 220/300, Train loss: 0.4434, Test loss: 9.3351, Accuracy: 0.2149\n",
      "Epoch: 221/300, Train loss: 0.4441, Test loss: 9.3197, Accuracy: 0.2149\n",
      "Epoch: 222/300, Train loss: 0.4441, Test loss: 9.3943, Accuracy: 0.2149\n",
      "Epoch: 223/300, Train loss: 0.4440, Test loss: 9.4134, Accuracy: 0.1897\n",
      "Epoch: 224/300, Train loss: 0.4441, Test loss: 9.4571, Accuracy: 0.2182\n",
      "Epoch: 225/300, Train loss: 0.4440, Test loss: 9.5145, Accuracy: 0.1880\n",
      "Epoch: 226/300, Train loss: 0.4436, Test loss: 9.5071, Accuracy: 0.2116\n",
      "Epoch: 227/300, Train loss: 0.4439, Test loss: 9.4631, Accuracy: 0.2149\n",
      "Epoch: 228/300, Train loss: 0.4437, Test loss: 9.5509, Accuracy: 0.1897\n",
      "Epoch: 229/300, Train loss: 0.4437, Test loss: 9.5459, Accuracy: 0.2166\n",
      "Epoch: 230/300, Train loss: 0.4439, Test loss: 9.5714, Accuracy: 0.2149\n",
      "Epoch: 231/300, Train loss: 0.4440, Test loss: 9.5214, Accuracy: 0.2166\n",
      "Epoch: 232/300, Train loss: 0.4440, Test loss: 9.5977, Accuracy: 0.2182\n",
      "Epoch: 233/300, Train loss: 0.4436, Test loss: 9.6706, Accuracy: 0.2116\n",
      "Epoch: 234/300, Train loss: 0.4439, Test loss: 9.7160, Accuracy: 0.2166\n",
      "Epoch: 235/300, Train loss: 0.4437, Test loss: 9.6305, Accuracy: 0.2166\n",
      "Epoch: 236/300, Train loss: 0.4445, Test loss: 9.6046, Accuracy: 0.1864\n",
      "Epoch: 237/300, Train loss: 0.4438, Test loss: 9.7214, Accuracy: 0.2133\n",
      "Epoch: 238/300, Train loss: 0.4441, Test loss: 9.7809, Accuracy: 0.2133\n",
      "Epoch: 239/300, Train loss: 0.4439, Test loss: 9.8475, Accuracy: 0.2149\n",
      "Epoch: 240/300, Train loss: 0.4437, Test loss: 9.7860, Accuracy: 0.2149\n",
      "Epoch: 241/300, Train loss: 0.4438, Test loss: 9.7770, Accuracy: 0.1880\n",
      "Epoch: 242/300, Train loss: 0.4438, Test loss: 9.7638, Accuracy: 0.2182\n",
      "Epoch: 243/300, Train loss: 0.4435, Test loss: 9.8254, Accuracy: 0.1897\n",
      "Epoch: 244/300, Train loss: 0.4440, Test loss: 9.8031, Accuracy: 0.2133\n",
      "Epoch: 245/300, Train loss: 0.4437, Test loss: 9.8650, Accuracy: 0.2100\n",
      "Epoch: 246/300, Train loss: 0.4439, Test loss: 9.9334, Accuracy: 0.2116\n",
      "Epoch: 247/300, Train loss: 0.4441, Test loss: 9.8805, Accuracy: 0.2116\n",
      "Epoch: 248/300, Train loss: 0.4438, Test loss: 9.9413, Accuracy: 0.1913\n",
      "Epoch: 249/300, Train loss: 0.4438, Test loss: 9.9487, Accuracy: 0.1880\n",
      "Epoch: 250/300, Train loss: 0.4436, Test loss: 9.9638, Accuracy: 0.2166\n",
      "Epoch: 251/300, Train loss: 0.4437, Test loss: 9.9599, Accuracy: 0.1864\n",
      "Epoch: 252/300, Train loss: 0.4437, Test loss: 10.0202, Accuracy: 0.2182\n",
      "Epoch: 253/300, Train loss: 0.4441, Test loss: 10.0657, Accuracy: 0.1897\n",
      "Epoch: 254/300, Train loss: 0.4440, Test loss: 10.0264, Accuracy: 0.1897\n",
      "Epoch: 255/300, Train loss: 0.4442, Test loss: 10.0597, Accuracy: 0.2067\n",
      "Epoch: 256/300, Train loss: 0.4437, Test loss: 10.0715, Accuracy: 0.2116\n",
      "Epoch: 257/300, Train loss: 0.4440, Test loss: 10.1257, Accuracy: 0.2149\n",
      "Epoch: 258/300, Train loss: 0.4441, Test loss: 10.1052, Accuracy: 0.1897\n",
      "Epoch: 259/300, Train loss: 0.4436, Test loss: 10.1555, Accuracy: 0.2133\n",
      "Epoch: 260/300, Train loss: 0.4436, Test loss: 10.1544, Accuracy: 0.2116\n",
      "Epoch: 261/300, Train loss: 0.4438, Test loss: 10.2321, Accuracy: 0.2133\n",
      "Epoch: 262/300, Train loss: 0.4437, Test loss: 10.2117, Accuracy: 0.2149\n",
      "Epoch: 263/300, Train loss: 0.4442, Test loss: 10.2282, Accuracy: 0.1897\n",
      "Epoch: 264/300, Train loss: 0.9243, Test loss: 6.7876, Accuracy: 0.2555\n",
      "Epoch: 265/300, Train loss: 0.8469, Test loss: 5.8359, Accuracy: 0.2599\n",
      "Epoch: 266/300, Train loss: 0.6513, Test loss: 6.6917, Accuracy: 0.2423\n",
      "Epoch: 267/300, Train loss: 0.5993, Test loss: 6.2826, Accuracy: 0.2505\n",
      "Epoch: 268/300, Train loss: 0.5875, Test loss: 6.3634, Accuracy: 0.2577\n",
      "Epoch: 269/300, Train loss: 0.5661, Test loss: 6.5055, Accuracy: 0.2610\n",
      "Epoch: 270/300, Train loss: 0.5567, Test loss: 6.4893, Accuracy: 0.2626\n",
      "Epoch: 271/300, Train loss: 0.5628, Test loss: 6.7505, Accuracy: 0.2593\n",
      "Epoch: 272/300, Train loss: 0.5602, Test loss: 6.6633, Accuracy: 0.2582\n",
      "Epoch: 273/300, Train loss: 0.5503, Test loss: 7.0702, Accuracy: 0.2544\n",
      "Epoch: 274/300, Train loss: 0.5556, Test loss: 6.6356, Accuracy: 0.2599\n",
      "Epoch: 275/300, Train loss: 0.5487, Test loss: 6.8204, Accuracy: 0.2527\n",
      "Epoch: 276/300, Train loss: 0.5448, Test loss: 6.9723, Accuracy: 0.2544\n",
      "Epoch: 277/300, Train loss: 0.5462, Test loss: 6.8518, Accuracy: 0.2593\n",
      "Epoch: 278/300, Train loss: 0.5507, Test loss: 7.1205, Accuracy: 0.2544\n",
      "Epoch: 279/300, Train loss: 0.5468, Test loss: 7.0886, Accuracy: 0.2478\n",
      "Epoch: 280/300, Train loss: 0.5657, Test loss: 6.8367, Accuracy: 0.2511\n",
      "Epoch: 281/300, Train loss: 0.5449, Test loss: 7.0053, Accuracy: 0.2527\n",
      "Epoch: 282/300, Train loss: 0.5399, Test loss: 7.1085, Accuracy: 0.2544\n",
      "Epoch: 283/300, Train loss: 0.5376, Test loss: 7.1116, Accuracy: 0.2495\n",
      "Epoch: 284/300, Train loss: 0.5372, Test loss: 7.2457, Accuracy: 0.2544\n",
      "Epoch: 285/300, Train loss: 0.5367, Test loss: 7.1525, Accuracy: 0.2527\n",
      "Epoch: 286/300, Train loss: 0.5351, Test loss: 7.2286, Accuracy: 0.2429\n",
      "Epoch: 287/300, Train loss: 0.5338, Test loss: 7.3580, Accuracy: 0.2495\n",
      "Epoch: 288/300, Train loss: 0.5341, Test loss: 7.4178, Accuracy: 0.2511\n",
      "Epoch: 289/300, Train loss: 0.5333, Test loss: 7.4628, Accuracy: 0.2527\n",
      "Epoch: 290/300, Train loss: 0.5326, Test loss: 7.5949, Accuracy: 0.2544\n",
      "Epoch: 291/300, Train loss: 0.5320, Test loss: 7.5290, Accuracy: 0.2511\n",
      "Epoch: 292/300, Train loss: 0.5324, Test loss: 7.6407, Accuracy: 0.2577\n",
      "Epoch: 293/300, Train loss: 0.5352, Test loss: 7.6043, Accuracy: 0.2451\n",
      "Epoch: 294/300, Train loss: 0.5326, Test loss: 7.7271, Accuracy: 0.2478\n",
      "Epoch: 295/300, Train loss: 0.5321, Test loss: 7.7250, Accuracy: 0.2462\n",
      "Epoch: 296/300, Train loss: 0.5323, Test loss: 7.9594, Accuracy: 0.2560\n",
      "Epoch: 297/300, Train loss: 0.5343, Test loss: 7.6662, Accuracy: 0.2478\n",
      "Epoch: 298/300, Train loss: 0.5359, Test loss: 7.7926, Accuracy: 0.2511\n",
      "Epoch: 299/300, Train loss: 0.5332, Test loss: 7.8342, Accuracy: 0.2511\n",
      "Epoch: 300/300, Train loss: 0.5331, Test loss: 8.0381, Accuracy: 0.2544\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 300\n",
    "print_every = 40\n",
    "train_losses, test_losses, accuracies = [], [], []\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_loss, running_test_losses, running_test_accuracy = 0, 0, 0\n",
    "    # print(f\"Epoch: {e+1}/{epochs}\")\n",
    "\n",
    "    for i, (sentences, labels) in enumerate(iter(train_loader)):\n",
    "\n",
    "        sentences.resize_(sentences.size()[0], 32* emb_dim)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model.forward(sentences)   # 1) Forward pass\n",
    "        train_loss = criterion(output, labels) # 2) Compute loss\n",
    "        train_loss.backward()                  # 3) Backward pass\n",
    "        optimizer.step()                 # 4) Update model\n",
    "        \n",
    "        running_loss += train_loss.item()\n",
    "        \n",
    "        # if i % print_every == 0:\n",
    "        #     print(f\"\\tIteration: {i}\\t Loss: {running_loss/print_every:.4f}\")\n",
    "        #     running_loss = 0\n",
    "    avg_running_loss = running_loss/len(train_loader)\n",
    "    train_losses.append(avg_running_loss)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (sentences_test, labels_test) in enumerate(iter(test_loader)):\n",
    "            sentences_test.resize_(sentences_test.size()[0], 32* emb_dim)\n",
    "\n",
    "            output_test = model.forward(sentences_test)\n",
    "            test_loss = criterion(output_test, labels_test)\n",
    "\n",
    "            running_test_losses += test_loss.item()\n",
    "\n",
    "            prediction_label = torch.argmax(output_test, dim=1)\n",
    "            running_test_accuracy += (prediction_label == labels_test).sum() / len(labels_test)\n",
    "        avg_test_loss = running_test_losses/len(test_loader)\n",
    "        test_losses.append(avg_test_loss)\n",
    "        avg_running_accuracy = running_test_accuracy/len(test_loader)\n",
    "        accuracies.append(avg_running_accuracy)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    print(f\"Epoch: {e+1}/{epochs}, Train loss: {avg_running_loss:.4f}, Test loss: {avg_test_loss:.4f}, Accuracy: {avg_running_accuracy:.4f}\" )\n",
    "\n",
    "torch.save({'model_state': model.state_dict()}, 'final_model')\n",
    "plt.plot(train_losses, label='Train loss')\n",
    "plt.plot(test_losses, label='Test losses')\n",
    "plt.plot(accuracies, label='Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "            \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7ec1a62599dbe491b495bbea6ed64b26266314bd43f2a5cdcc432a9a3a8883da"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
