{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batches, Batch Normalization and Dropout\n",
    "\n",
    "In this workbook you can experiment what you learnt about how to make batches out of your data, how to perform batch normalization and dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f87b195dfb0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "torch.manual_seed(44)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data from data/batches_norm_drop.csv, then take a look at them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1  2\n",
      "0  0.350140  4.248592  0\n",
      "1  0.950728  3.528855  0\n",
      "2  1.371517  3.149416  0\n",
      "3  0.268221  4.337209  0\n",
      "4  1.881996  1.515387  0\n",
      "0    250\n",
      "1    250\n",
      "2    250\n",
      "Name: 2, dtype: int64\n",
      "(750, 3)\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "data = pd.read_csv(\"/Users/szokirov/Documents/GitHub/strive_practice/Chapter 03/04. DataLoader/data/batches_norm_drop.csv\", header=None)\n",
    "print(data.head())\n",
    "print(data[2].value_counts())\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you are ready to code your own function to create batches. If needed rewatch the video we provided in Eduflow.\n",
    "\n",
    "**Extra challange:**    Are you able to split between train and test _**without**_ using sklearn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchify(x_train, x_test, y_train, y_test, batch_size):\n",
    "#YOUR CODE HERE\n",
    "    num_batch = x_train.shape[0] // batch_size\n",
    "    num_batch_test = x_test.shape[0] // batch_size\n",
    "\n",
    "    indexes_train = np.random.permutation(x_train.shape[0])\n",
    "    indexes_test = np.random.permutation(x_test.shape[0])\n",
    "\n",
    "    x_train = x_train[indexes_train]\n",
    "    x_test = x_test[indexes_test]\n",
    "\n",
    "    y_train = y_train[indexes_train]\n",
    "    y_test = y_test[indexes_test]\n",
    "\n",
    "    x_train = x_train[ :batch_size * num_batch ].reshape(num_batch, batch_size, x_train.shape[1])\n",
    "    y_train = y_train[ :batch_size * num_batch ].reshape(num_batch, batch_size, 1)\n",
    "\n",
    "    x_test = x_test[ :batch_size * num_batch_test ].reshape(num_batch_test, batch_size, x_test.shape[1])\n",
    "    y_test = y_test[ :batch_size * num_batch_test ].reshape(num_batch_test, batch_size, 1)\n",
    "\n",
    "    return x_train, x_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of samples in train: 600\n",
      "Total Number of samples in test: 150\n"
     ]
    }
   ],
   "source": [
    "data = data.sample(frac=1)\n",
    "x = data.iloc[:, :2].values\n",
    "y = data.iloc[:, -1].values\n",
    "#splitting the data\n",
    "train_ratio = 0.8\n",
    "n_train = math.floor(train_ratio * x.shape[0])\n",
    "n_test = math.ceil((1-train_ratio) * x.shape[0])\n",
    "x_train = x[:n_train]\n",
    "y_train = y[:n_train]\n",
    "x_test = x[n_train:]\n",
    "y_test = y[n_train:]\n",
    "print(\"Total Number of samples in train:\",x_train.shape[0])\n",
    "print(\"Total Number of samples in test:\",x_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch\n",
    "x_train_batch, x_test_batch, y_train_batch, y_test_batch = batchify(x_train, x_test, y_train, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time to create your model! Remember to include the new tricks you learnt (batch normalization and dropout)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "class Network(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Network, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size[0])\n",
    "        self.fc2 = nn.Linear(hidden_size[0], hidden_size[1])\n",
    "        self.fc3 = nn.Linear(hidden_size[1], 1)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x = self._forward_features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (fc1): Linear(in_features=2, out_features=20, bias=True)\n",
       "  (fc2): Linear(in_features=20, out_features=10, bias=True)\n",
       "  (fc3): Linear(in_features=10, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.25, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_size = [20, 10]\n",
    "model = Network(2, hidden_size)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train your model and evaluate it. **Extra challenge**: try to figure out how you can tell if batch norm and dropout are effective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/szokirov/Documents/GitHub/strive_practice/Chapter 03/04. DataLoader/Batches_BatchNorm_Dropout.ipynb Cell 14'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/szokirov/Documents/GitHub/strive_practice/Chapter%2003/04.%20DataLoader/Batches_BatchNorm_Dropout.ipynb#ch0000009?line=9'>10</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch, (x_train_batch, y_train_batch) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mzip\u001b[39m(x_train, y_train)):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/szokirov/Documents/GitHub/strive_practice/Chapter%2003/04.%20DataLoader/Batches_BatchNorm_Dropout.ipynb#ch0000009?line=10'>11</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/szokirov/Documents/GitHub/strive_practice/Chapter%2003/04.%20DataLoader/Batches_BatchNorm_Dropout.ipynb#ch0000009?line=11'>12</a>\u001b[0m     train_preds \u001b[39m=\u001b[39m model(x_train_batch)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/szokirov/Documents/GitHub/strive_practice/Chapter%2003/04.%20DataLoader/Batches_BatchNorm_Dropout.ipynb#ch0000009?line=12'>13</a>\u001b[0m     losses \u001b[39m=\u001b[39m loss(train_preds, y_train_batch)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/szokirov/Documents/GitHub/strive_practice/Chapter%2003/04.%20DataLoader/Batches_BatchNorm_Dropout.ipynb#ch0000009?line=13'>14</a>\u001b[0m     current_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m losses\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/szokirov/opt/anaconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/szokirov/opt/anaconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/szokirov/opt/anaconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///Users/szokirov/opt/anaconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///Users/szokirov/opt/anaconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///Users/szokirov/opt/anaconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/szokirov/opt/anaconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/Users/szokirov/Documents/GitHub/strive_practice/Chapter 03/04. DataLoader/Batches_BatchNorm_Dropout.ipynb Cell 10'\u001b[0m in \u001b[0;36mNetwork.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/szokirov/Documents/GitHub/strive_practice/Chapter%2003/04.%20DataLoader/Batches_BatchNorm_Dropout.ipynb#ch0000007?line=9'>10</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/szokirov/Documents/GitHub/strive_practice/Chapter%2003/04.%20DataLoader/Batches_BatchNorm_Dropout.ipynb#ch0000007?line=10'>11</a>\u001b[0m     \u001b[39m# x = self._forward_features(x)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/szokirov/Documents/GitHub/strive_practice/Chapter%2003/04.%20DataLoader/Batches_BatchNorm_Dropout.ipynb#ch0000007?line=11'>12</a>\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mview(x\u001b[39m.\u001b[39;49msize(\u001b[39m0\u001b[39;49m), \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/szokirov/Documents/GitHub/strive_practice/Chapter%2003/04.%20DataLoader/Batches_BatchNorm_Dropout.ipynb#ch0000007?line=12'>13</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/szokirov/Documents/GitHub/strive_practice/Chapter%2003/04.%20DataLoader/Batches_BatchNorm_Dropout.ipynb#ch0000007?line=13'>14</a>\u001b[0m     x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc1(x))\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "num_epoch = 5\n",
    "for epoch in range(num_epoch):\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    model.train()\n",
    "    print(f\"Starting epoch{epoch}\")\n",
    "    current_loss = 0\n",
    "    for batch, (x_train_batch, y_train_batch) in enumerate(zip(x_train, y_train)):\n",
    "        optimizer.zero_grad()\n",
    "        train_preds = model(x_train_batch)\n",
    "        losses = loss(train_preds, y_train_batch)\n",
    "        current_loss += losses.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch % 1000==0:\n",
    "            print('Train Epoch: {} \\tLoss: {:.8f}'.format(epoch,loss.item()))\n",
    "        train_loss.append(current_loss/x_train.shape[0])\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        running_loss = 0\n",
    "        for batch_id, (x_test_batch, y_test_batch) in enumerate(zip(x_test, y_test)):\n",
    "            test_preds = model(x_test_batch)\n",
    "            losses = loss(test_preds, y_test_batch)\n",
    "            running_loss += losses.item()\n",
    "        test_loss.append(running_loss/x_test.shape[0])\n",
    "    model.eval()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f12c5d7f0baae8022573a61a8d5591a3788530288ea52bc9ad65d8d764f8ff68"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
